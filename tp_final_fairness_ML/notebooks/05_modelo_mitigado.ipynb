{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0922741b",
   "metadata": {},
   "source": [
    "# Mitigación de sesgo en el modelo original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347a0a1",
   "metadata": {},
   "source": [
    "## Índice de Contenido\n",
    "\n",
    "1. [Preparación del entorno y carga de datos](#1-Preparación-del-entorno-y-carga-de-datos)\n",
    "2. [Primer método de mitigación](#2-Primer-método-de-mitigación)\n",
    "    - [Aplicación del método y entrenamiento del modelo](#2.1-Aplicación-del-método-y-entrenamiento-del-modelo)\n",
    "    - [Evaluación del modelo mediante métricas de clasificación](#2.2-Evaluación-del-modelo-mediante-métricas-de-clasificación)\n",
    "3. [Segundo método de mitigación](#3-Segundo-método-de-mitigación)\n",
    "    - [Aplicación del método y entrenamiento del modelo](#3.1-Aplicación-del-método-y-entrenamiento-del-modelo)\n",
    "    - [Evaluación del modelo mediante métricas de clasificación](#3.2-Evaluación-del-modelo-mediante-métricas-de-clasificación)\n",
    "4. [Evaluación de equidad de modelos mitigados](#4-Evaluación-de-equidad-de-modelos-mitigados)\n",
    "5. [Resumen y conclusiones](#5-Resumen-y-conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7443f17",
   "metadata": {},
   "source": [
    "### Si tomamos como umbral 0.1 se dejaria de cumplir Equalized Odds, por lo que intentaremos mitigar la metrica de fpr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965bb257",
   "metadata": {},
   "source": [
    "# 1. Preparación del entorno y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fc905426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carga de datos\n",
    "ruta_archivo = os.path.join('..', 'data', 'processed', 'df_genero_procesado.csv')\n",
    "g_credit_data = pd.read_csv(ruta_archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80433921",
   "metadata": {},
   "source": [
    "# 2. Primer método de mitigación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ef4e0",
   "metadata": {},
   "source": [
    "#### Como el primer metodo de mitigacion será pre-processing , debemos utilizar nuevamente los datos previos al entrenamiento de cualquier modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3e7a6",
   "metadata": {},
   "source": [
    "## 2.1 Aplicación del método y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f85e56d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de X_train_design: (800, 18)\n",
      "Dimensiones de X_test_design: (200, 18)\n",
      "Distribución de clases en el conjunto de entrenamiento: [241 559]\n",
      "Distribución de clases en el conjunto de prueba: [ 59 141]\n"
     ]
    }
   ],
   "source": [
    "# Separamos variables predictoras (X) y variable objetivo (y)\n",
    "\n",
    "X = g_credit_data.drop(columns=['target'])\n",
    "y = g_credit_data['target']\n",
    "indices = X.index\n",
    "\n",
    "# Dividimos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X.values, y.values, indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns, index=idx_test)\n",
    "y_test = pd.Series(y_test, name='target', index=idx_test)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns, index=idx_train)\n",
    "y_train = pd.Series(y_train, name='target', index=idx_train)\n",
    "\n",
    "print(f\"Dimensiones de X_train_design: {X_train_design.shape}\")\n",
    "print(f\"Dimensiones de X_test_design: {X_test_design.shape}\")\n",
    "print(f\"Distribución de clases en el conjunto de entrenamiento: {np.bincount(y_train)}\")\n",
    "print(f\"Distribución de clases en el conjunto de prueba: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4713a9",
   "metadata": {},
   "source": [
    "#### Se ejecuta el Baseline con modelo LogisticRegressor de Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "879b23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.bias.metrics import classification_bias_metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from holisticai.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Normalizamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "modelo = LogisticRegression(random_state=42, max_iter=1000)\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test = modelo.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a3ee51d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Value  Reference\n",
      "Metric                                                 \n",
      "Statistical Parity                  0.083333          0\n",
      "Disparate Impact                    1.111111          1\n",
      "Four Fifths Rule                    0.900000          1\n",
      "Cohen D                             0.213470          0\n",
      "2SD Rule                            1.348838          0\n",
      "Equality of Opportunity Difference  0.049774          0\n",
      "False Positive Rate Difference      0.148459          0\n",
      "Average Odds Difference             0.099117          0\n",
      "Accuracy Difference                -0.003968          0\n",
      "Baseline accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "baseline = classification_bias_metrics(X_test['genre_male']==1, X_test['genre_male']==0, y_pred_test, y_test, metric_type='both')\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "metrics['Baseline'] = baseline\n",
    "print(baseline)\n",
    "print(f\"Baseline accuracy: {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a67c1",
   "metadata": {},
   "source": [
    "#### Notamos que aun ajustando un regresor de Scikit-learn sigue dando una diferencia en fpr mayor a 0.1.\n",
    "#### Utilizamos el metodo pre-processing CorrelationRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e6e2d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Value  Reference\n",
      "Metric                                                 \n",
      "Statistical Parity                 -0.097222          0\n",
      "Disparate Impact                    0.888889          1\n",
      "Four Fifths Rule                    0.888889          1\n",
      "Cohen D                            -0.246777          0\n",
      "2SD Rule                           -1.558155          0\n",
      "Equality of Opportunity Difference -0.056561          0\n",
      "False Positive Rate Difference     -0.205882          0\n",
      "Average Odds Difference            -0.131222          0\n",
      "Accuracy Difference                 0.027778          0\n",
      "Preprocessing model accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "from holisticai.bias.mitigation import CorrelationRemover \n",
    "mitigator = CorrelationRemover()\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline(steps=[('scalar', StandardScaler()), (\"bm_preprocessing\", mitigator), (\"estimator\", model),])\n",
    "pipeline.fit(X_train, y_train, bm__group_a=X_train['genre_male'] == 1, bm__group_b=X_train['genre_male'] == 0)\n",
    "\n",
    "y_pred_pipeline = pipeline.predict(X_test, bm__group_a=X_test['genre_male'] == 1, bm__group_b=X_test['genre_male'] == 0)\n",
    "\n",
    "metrics_preprocessing_correlationRemover = classification_bias_metrics(X_test['genre_male']==1, X_test['genre_male']==0, y_pred_pipeline, y_test, metric_type='both')\n",
    "\n",
    "accuracy_preprocessing_correlationRemover = accuracy_score(y_test, y_pred_pipeline)\n",
    "\n",
    "metrics['CorrelationRemover'] = metrics_preprocessing_correlationRemover\n",
    "print(metrics_preprocessing_correlationRemover)\n",
    "print(f\"Preprocessing model accuracy: {accuracy_preprocessing_correlationRemover:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466392de",
   "metadata": {},
   "source": [
    "## 2.2 Evaluación del modelo mediante métricas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a0bf2",
   "metadata": {},
   "source": [
    "#### El modelo empeoró su performance con el fpr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dea1b",
   "metadata": {},
   "source": [
    "# 3. Segundo método de mitigación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f43e86",
   "metadata": {},
   "source": [
    "### Utilizamos el metodo Inprocessing PrejudiceRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31858a3",
   "metadata": {},
   "source": [
    "## 3.1 Aplicación del método y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8b608273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[elapsed time: 00:00:00 | iter:6/100 | loss:399.3788]\n",
      "[elapsed time: 00:00:00 | Best Loss : 399.3788]\n",
      "                                       Value  Reference\n",
      "Metric                                                 \n",
      "Statistical Parity                 -0.033730          0\n",
      "Disparate Impact                    0.959811          1\n",
      "Four Fifths Rule                    0.959811          1\n",
      "Cohen D                            -0.086919          0\n",
      "2SD Rule                           -0.551587          0\n",
      "Equality of Opportunity Difference -0.046757          0\n",
      "False Positive Rate Difference     -0.016807          0\n",
      "Average Odds Difference            -0.031782          0\n",
      "Accuracy Difference                -0.021825          0\n",
      "Inprocessing model accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "# Define inprocessing model\n",
    "from holisticai.bias.mitigation import PrejudiceRemover\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "mitigator = PrejudiceRemover(maxiter=100, fit_intercept=True, verbose=1, print_interval=1).transform_estimator(model)\n",
    "\n",
    "# Standardize data and fit model\n",
    "scaler = StandardScaler()\n",
    "group_a_train = X_train['genre_male'] == 1\n",
    "group_b_train = X_train['genre_male'] == 0\n",
    "group_a_test = X_test['genre_male'] == 1\n",
    "group_b_test = X_test['genre_male'] == 0\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "mitigator.fit(X_train, y_train, group_a_train, group_b_train)\n",
    "\n",
    "# Standardize data and predict\n",
    "X_test = scaler.transform(X_test)\n",
    "y_pred = mitigator.predict(X_test, group_a_test, group_b_test)\n",
    "\n",
    "# Evaluate bias metrics\n",
    "metrics_prejudice = classification_bias_metrics(group_a_test, group_b_test, y_pred, y_test, metric_type='both')\n",
    "metrics['PrejudiceRemover'] = metrics_prejudice\n",
    "print(metrics['PrejudiceRemover'])\n",
    "print(f\"Inprocessing model accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91db36",
   "metadata": {},
   "source": [
    "## 3.2 Evaluación del modelo mediante métricas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834786d4",
   "metadata": {},
   "source": [
    "### El modelo mejoró notablemente su diferencia en fpr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccc6e5",
   "metadata": {},
   "source": [
    "# 4. Evaluación de equidad de modelos mitigados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780c150",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "897d3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61925_row0_col2, #T_61925_row1_col2, #T_61925_row2_col2, #T_61925_row3_col2, #T_61925_row4_col2, #T_61925_row5_col2, #T_61925_row6_col2, #T_61925_row7_col2, #T_61925_row8_col0 {\n",
       "  background-color: mediumseagreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61925\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61925_level0_col0\" class=\"col_heading level0 col0\" >Baseline</th>\n",
       "      <th id=\"T_61925_level0_col1\" class=\"col_heading level0 col1\" >CorrelationRemover</th>\n",
       "      <th id=\"T_61925_level0_col2\" class=\"col_heading level0 col2\" >PrejudiceRemover</th>\n",
       "      <th id=\"T_61925_level0_col3\" class=\"col_heading level0 col3\" >Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row0\" class=\"row_heading level0 row0\" >Statistical Parity</th>\n",
       "      <td id=\"T_61925_row0_col0\" class=\"data row0 col0\" >0.083333</td>\n",
       "      <td id=\"T_61925_row0_col1\" class=\"data row0 col1\" >-0.097222</td>\n",
       "      <td id=\"T_61925_row0_col2\" class=\"data row0 col2\" >-0.033730</td>\n",
       "      <td id=\"T_61925_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row1\" class=\"row_heading level0 row1\" >Disparate Impact</th>\n",
       "      <td id=\"T_61925_row1_col0\" class=\"data row1 col0\" >1.111111</td>\n",
       "      <td id=\"T_61925_row1_col1\" class=\"data row1 col1\" >0.888889</td>\n",
       "      <td id=\"T_61925_row1_col2\" class=\"data row1 col2\" >0.959811</td>\n",
       "      <td id=\"T_61925_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row2\" class=\"row_heading level0 row2\" >Four Fifths Rule</th>\n",
       "      <td id=\"T_61925_row2_col0\" class=\"data row2 col0\" >0.900000</td>\n",
       "      <td id=\"T_61925_row2_col1\" class=\"data row2 col1\" >0.888889</td>\n",
       "      <td id=\"T_61925_row2_col2\" class=\"data row2 col2\" >0.959811</td>\n",
       "      <td id=\"T_61925_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row3\" class=\"row_heading level0 row3\" >Cohen D</th>\n",
       "      <td id=\"T_61925_row3_col0\" class=\"data row3 col0\" >0.213470</td>\n",
       "      <td id=\"T_61925_row3_col1\" class=\"data row3 col1\" >-0.246777</td>\n",
       "      <td id=\"T_61925_row3_col2\" class=\"data row3 col2\" >-0.086919</td>\n",
       "      <td id=\"T_61925_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row4\" class=\"row_heading level0 row4\" >2SD Rule</th>\n",
       "      <td id=\"T_61925_row4_col0\" class=\"data row4 col0\" >1.348838</td>\n",
       "      <td id=\"T_61925_row4_col1\" class=\"data row4 col1\" >-1.558155</td>\n",
       "      <td id=\"T_61925_row4_col2\" class=\"data row4 col2\" >-0.551587</td>\n",
       "      <td id=\"T_61925_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row5\" class=\"row_heading level0 row5\" >Equality of Opportunity Difference</th>\n",
       "      <td id=\"T_61925_row5_col0\" class=\"data row5 col0\" >0.049774</td>\n",
       "      <td id=\"T_61925_row5_col1\" class=\"data row5 col1\" >-0.056561</td>\n",
       "      <td id=\"T_61925_row5_col2\" class=\"data row5 col2\" >-0.046757</td>\n",
       "      <td id=\"T_61925_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row6\" class=\"row_heading level0 row6\" >False Positive Rate Difference</th>\n",
       "      <td id=\"T_61925_row6_col0\" class=\"data row6 col0\" >0.148459</td>\n",
       "      <td id=\"T_61925_row6_col1\" class=\"data row6 col1\" >-0.205882</td>\n",
       "      <td id=\"T_61925_row6_col2\" class=\"data row6 col2\" >-0.016807</td>\n",
       "      <td id=\"T_61925_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row7\" class=\"row_heading level0 row7\" >Average Odds Difference</th>\n",
       "      <td id=\"T_61925_row7_col0\" class=\"data row7 col0\" >0.099117</td>\n",
       "      <td id=\"T_61925_row7_col1\" class=\"data row7 col1\" >-0.131222</td>\n",
       "      <td id=\"T_61925_row7_col2\" class=\"data row7 col2\" >-0.031782</td>\n",
       "      <td id=\"T_61925_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61925_level0_row8\" class=\"row_heading level0 row8\" >Accuracy Difference</th>\n",
       "      <td id=\"T_61925_row8_col0\" class=\"data row8 col0\" >-0.003968</td>\n",
       "      <td id=\"T_61925_row8_col1\" class=\"data row8 col1\" >0.027778</td>\n",
       "      <td id=\"T_61925_row8_col2\" class=\"data row8 col2\" >-0.021825</td>\n",
       "      <td id=\"T_61925_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x136e6cd10>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison table of bias metrics\n",
    "\n",
    "keys = ['Baseline', 'CorrelationRemover', 'PrejudiceRemover', 'Reference']\n",
    "comparison = pd.concat([baseline['Value'], metrics_preprocessing_correlationRemover['Value'], metrics_prejudice], axis=1)\n",
    "comparison.columns = keys\n",
    "\n",
    "def highlight_closest(s):\n",
    "    reference = s['Reference']\n",
    "    differences = s.drop('Reference').apply(lambda x: abs(x - reference))\n",
    "    closest = differences.idxmin()\n",
    "    return ['background-color: mediumseagreen' if x == s[closest] else '' for x in s]\n",
    "\n",
    "comparison_highlighted = comparison.style.apply(highlight_closest, axis=1)\n",
    "comparison_highlighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d3fbe",
   "metadata": {},
   "source": [
    "# 5. Resumen y conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ab716",
   "metadata": {},
   "source": [
    "#### El modelo mitigado con PrejudiceRemover es un modelo que cumple mejora casi en su totalidad las metricas que miden fairness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
